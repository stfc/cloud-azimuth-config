---
name: Clean up stale CI resources

permissions:
  contents: read
  packages: write
  # To report GitHub Actions status checks
  statuses: write
  id-token: write

on:
  schedule:
    # Every 2 hours at 8 minutes past
    - cron: "8 0/2 * * *"
  workflow_dispatch:
    # checkov:skip=CKV_GHA_7: "The build output cannot be affected by user parameters other than the build entry point and the top-level source location. GitHub Actions workflow_dispatch inputs MUST be empty. "
    inputs:
      delete-resources:
        type: boolean
        description: "Delete resources older than 6h"
        required: true
      delete-all-keypairs:
        type: boolean
        description: "Delete all CI user keypairs"
        required: true
      target-cloud:
        description: >-
          The cloud to target for the run.
          Leave blank to use the default cloud.
        type: choice
        options:
          - ""
          - arcus
          - leafcloud

jobs:
  ci-cleanup:
    name: Clean up stale CI resources
    if: github.repository == 'azimuth-cloud/azimuth-config'
    runs-on: ubuntu-latest
    steps:
      - name: Setup Python
        uses: actions/setup-python@v5

      - name: Generate clouds.yaml
        run: |
          cat << EOF > clouds.yaml
          ${{ secrets.OS_CLOUDS }}
          EOF

      - name: Install OpenStack client
        run: |
          pip install python-openstackclient

      - name: Clean up instances and attached volumes over 6 hours old
        if: ${{ github.event_name == 'schedule' || inputs.delete-resources }}
        run: |
          result=0
          changes_before=$(date -Imin -d -6hours)
          for status in ACTIVE BUILD ERROR SHUTOFF; do
              for instance in $(openstack server list --unlocked --format value --column ID --changes-before "$changes_before" --status $status); do
                  echo "Cleaning up $status instance $instance"
                  openstack server show "$instance"
                  echo "Getting volumes for instance $instance"
                  volumes=$(openstack server volume list -f value -c "Volume ID" "$instance")
                  keypair=$(openstack server show "$instance" -f value -c key_name)
                  if ! openstack server delete "$instance"; then
                      echo "Failed to delete $status instance $instance"
                      result=1
                  fi
                  echo "Deleting keypair for instance $instance"
                  # This shouldn't fail, but might if the keypair is in-use elsewhere
                  openstack keypair delete "$keypair" || true
                  for volume in $volumes; do
                    echo "Cleaning up volume $volume from instance $instance"
                    openstack volume show "$volume"
                    if ! openstack volume delete "$volume"; then
                      echo "Failed to delete volume $volume"
                      result=1
                    fi
                  done
              done
          done
          exit $result
        env:
          OS_CLOUD: ${{ inputs.target-cloud || vars.TARGET_CLOUD }}
        
      - name: Clean up all SSH keypairs
        if: ${{ inputs.delete-all-keypairs }}
        run: |
          for keypair in $(openstack keypair list --format value -c Name); do
            if [[ "$keypair" =~ ^azimuth- || "$keypair" =~ ^packer_ ]]; then
              openstack keypair delete "$keypair"
              echo "Deleted keypair $keypair"
            fi
          done
        env:
          OS_CLOUD: ${{ inputs.target-cloud || vars.TARGET_CLOUD }}
