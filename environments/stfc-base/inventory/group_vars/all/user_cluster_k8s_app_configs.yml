---
azimuth_capi_operator_app_templates_jupyterhub_default_values:
  jupyterhub:
    prePuller:
      # Disabled because of large GPU images
      # TODO: See https://z2jh.jupyter.org/en/latest/resources/reference.html#prepuller-pullprofilelistimages for alternatives should we wish to renable
      # I.e. we could add non-gpu images to extraImages
      hook:
        enabled: false
      continuous:
        enabled: false

    singleuser:
      startTimeout: 1200 # Increase as GPU image is large. Needs to be global instead of "per profile" due to bug:
      # https://discourse.jupyter.org/t/spawn-failed-timeout-even-when-start-timeout-is-set-to-3600-seconds/8098
      profileList:
        - display_name: "Python environment (minimal)"
          description: "Minimal Python environment"
          default: true
          kubespawner_override:
            image: quay.io/jupyter/minimal-notebook:latest
        - display_name: "Data Science Notebook"
          description: "Libraries for data analysis in Python, R and Julia."
          kubespawner_override:
            image: quay.io/jupyter/datascience-notebook:latest
        - display_name: "GPU-enabled Machine Learning environment"
          description: >
            Support for GPU-enabled machine learning in Python.
            JupyterLab servers of this type will only start on node groups
            including nodes that have access to an NVIDIA GPU.
            [It may take 5-10 minutes for the gpu-operator to install required
            CUDA drivers on newly provisioned GPU nodes, until there may not be GPU capacity/
            no nodes may match the GPU-requirement affinity/selector.]
          kubespawner_override:
            image: cschranz/gpu-jupyter:v1.9_cuda-12.6_ubuntu-24.04_python-only
            # Guarantee is required, this has the added effect of ensuring scheduling only happens
            # after GPU operator has finished installing drivers etc, as it sets capacity
            # after it is done. It also prevents autoscaling when a node is already in initial setup
            extra_resource_guarantees: {"nvidia.com/gpu": "1"}
            # A limit is required else it errors. "Limit must be set for non overcommitable resources". Can increase if needed.
            extra_resource_limits: {"nvidia.com/gpu": "1"} 
            # Only attempt spawning on GPU-enabled node groups
            node_affinity_required:
              - matchExpressions:
                  - key: nvidia.com/gpu.present
                    operator: Exists
            tolerations: # Incase we add taint in future to reduce uncessary GPU usage. See nvidiaGPUOperator.release.values.node-feature-discovery.master.config.enableTaints.
              - key: "nvidia.com/gpu"
                operator: "Exists"
                effect: "NoSchedule"
    # TODO: Add custom image option, take details from azimuth-ui.schema.yaml
    # Might need to fork for that...
    hub:
      extraConfig:
        # We need to overwrite remoteuser.py to add redirect_to_server=False to give profile options
        remoteuser.py: |
          from jupyterhub.auth import Authenticator
          from jupyterhub.handlers import BaseHandler

          from tornado import web

          class RemoteUserLoginHandler(BaseHandler):
              def get(self):
                  remote_user = self.request.headers.get("X-Remote-User")
                  if not remote_user:
                      raise web.HTTPError(401)
                  user = self.user_from_username(remote_user)
                  self.set_login_cookie(user)
                  next_url = self.get_next_url(user)
                  self.redirect(next_url)

          class RemoteUserAuthenticator(Authenticator):
              def get_handlers(self, app):
                  return [(r'/login', RemoteUserLoginHandler)]

              async def authenticate(self, *args, **kwargs):
                  raise NotImplementedError()

          c.JupyterHub.redirect_to_server = False
          c.JupyterHub.authenticator_class = RemoteUserAuthenticator
